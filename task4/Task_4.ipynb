{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 5.\n",
    "\n",
    "Загрузите [данные по изменению температуры поверхности земли](https://www.kaggle.com/datasets/berkeleyearth/climate-change-earth-surface-temperature-data). Для этого может понадобится зарегистрироваться на [Kaggle](https://kaggle.com). Затем нужно будет работать с данными, которые содержатся в файле **GlobalLandTemperaturesByMajorCity.csv**\n",
    "\n",
    "**NB** Все подсчеты необходимо делать с помощью `PySpark`, без применения `pandas api`. Можно использоать `SQL`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/07/03 16:09:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/07/03 16:09:35 WARN TaskSetManager: Stage 0 contains a task of very large size (1003 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+-------+-------------+--------+---------+\n",
      "|        dt|AverageTemperature|AverageTemperatureUncertainty|   City|      Country|Latitude|Longitude|\n",
      "+----------+------------------+-----------------------------+-------+-------------+--------+---------+\n",
      "|1849-01-01|            26.704|                        1.435|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
      "|1849-02-01|            27.434|                        1.362|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
      "|1849-03-01|            28.101|                        1.612|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
      "|1849-04-01|             26.14|           1.3869999999999998|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
      "|1849-05-01|            25.427|                          1.2|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
      "|1849-06-01|            24.844|                        1.402|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
      "|1849-07-01|24.058000000000003|                        1.254|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
      "|1849-08-01|            23.576|                        1.265|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
      "|1849-09-01|            23.662|                        1.226|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
      "|1849-10-01|            25.263|                        1.175|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
      "+----------+------------------+-----------------------------+-------+-------------+--------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_date\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"PySpark\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "pandas_df = pd.read_csv('GlobalLandTemperaturesByMajorCity.csv')\n",
    "df = spark.createDataFrame(pandas_df)\n",
    "\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 4.1 (1 балл)\n",
    "\n",
    "В последующих заданиях будут учитываться данные начиная с 01.01.1950. Для этого создайте новый `DataFrame`, в котором удалены все строки до 01.01.1950. Используйте созданный DataFrame в последующих заданиях.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+-------+-------------+--------+---------+\n",
      "|        dt|AverageTemperature|AverageTemperatureUncertainty|   City|      Country|Latitude|Longitude|\n",
      "+----------+------------------+-----------------------------+-------+-------------+--------+---------+\n",
      "|1950-01-01|26.773000000000003|                        0.239|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
      "|1950-02-01|27.526999999999997|                        0.348|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
      "|1950-03-01|            28.344|                        0.431|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
      "|1950-04-01|             27.83|                        0.467|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
      "|1950-05-01|            26.896|                        0.248|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
      "|1950-06-01|            25.454|                        0.209|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
      "|1950-07-01|            24.878|                        0.403|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
      "|1950-08-01|            23.734|                        0.314|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
      "|1950-09-01|            24.253|                        0.257|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
      "|1950-10-01|            25.266|                        0.191|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
      "+----------+------------------+-----------------------------+-------+-------------+--------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/03 16:09:43 WARN TaskSetManager: Stage 1 contains a task of very large size (1003 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/07/03 16:09:43 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "clear_df = df.filter(col('dt') >= '1950-01-01').filter(col('AverageTemperature').isNotNull())\n",
    "clear_df.createOrReplaceGlobalTempView(\"T\")\n",
    "clear_df.show(10)\n",
    "clear_df = clear_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 4.2 (2 балла)\n",
    "\n",
    "Найдите город, для которого выборочная дисперсия температур на приведенных данных максимальна. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/03 16:12:45 WARN TaskSetManager: Stage 8 contains a task of very large size (1003 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(City='Harbin', TemperatureVariance=218.898615951821)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import variance\n",
    "\n",
    "variance_data = clear_df.groupBy(\"City\").agg(variance(col(\"AverageTemperature\")).alias(\"TemperatureVariance\"))\n",
    "variance_data.orderBy(col(\"TemperatureVariance\").desc()).first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 4.3 (2 баллов)\n",
    "\n",
    "Посчитайте данные по среднегодовой температуре в Санкт-Петербурге. Определите года, в которых средняя температура была выше, чем в предыдущем  и последующем году. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/03 16:17:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/07/03 16:17:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/07/03 16:17:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/07/03 16:17:13 WARN TaskSetManager: Stage 65 contains a task of very large size (1003 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/07/03 16:17:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/07/03 16:17:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/07/03 16:17:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/07/03 16:17:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/07/03 16:17:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/07/03 16:17:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(Year=1953),\n",
       " Row(Year=1957),\n",
       " Row(Year=1959),\n",
       " Row(Year=1961),\n",
       " Row(Year=1964),\n",
       " Row(Year=1967),\n",
       " Row(Year=1972),\n",
       " Row(Year=1975),\n",
       " Row(Year=1977),\n",
       " Row(Year=1979),\n",
       " Row(Year=1983),\n",
       " Row(Year=1986),\n",
       " Row(Year=1989),\n",
       " Row(Year=1992),\n",
       " Row(Year=1995),\n",
       " Row(Year=1997),\n",
       " Row(Year=2000),\n",
       " Row(Year=2002),\n",
       " Row(Year=2005),\n",
       " Row(Year=2008),\n",
       " Row(Year=2011)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import year, avg, month\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import lag, lead\n",
    "\n",
    "spb_data = clear_df.filter(col('City') == 'Saint Petersburg')\n",
    "spb_data = spb_data.withColumn('Year', year(col('dt')))\n",
    "avg_annual_temp_spb = spb_data.groupBy('Year').agg(avg(col('AverageTemperature')).alias('YeaAverageTemperature'))\n",
    "\n",
    "avg_annual_temp_spb = avg_annual_temp_spb.orderBy('Year')\n",
    "\n",
    "window_spec = Window.orderBy(\"Year\")\n",
    "avg_annual_temp_spb = avg_annual_temp_spb.withColumn(\"PrevYearTemp\", lag(\"YeaAverageTemperature\").over(window_spec))\n",
    "avg_annual_temp_spb = avg_annual_temp_spb.withColumn(\"NextYearTemp\", lead(\"YeaAverageTemperature\").over(window_spec))\n",
    "result = avg_annual_temp_spb.filter(\n",
    "    (col(\"YeaAverageTemperature\") > col(\"PrevYearTemp\")) & (col(\"YeaAverageTemperature\") > col(\"NextYearTemp\"))\n",
    ")\n",
    "\n",
    "result.select(\"Year\").collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 4.4 (4 балла)\n",
    "\n",
    "Найдите города, для которых: \n",
    "1. Разница между максимальным и минимальным значением среднегодовой температуры в выборке максимальна.\n",
    "2. Самая большая средняя разница между средней температурой января и средней температурой июля.\n",
    "3. Наибольшее среднее количество месяцев с отрицательной температурой в году."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Максимальная разница между максимальной и минимальной среднегодовой температурой\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/03 16:14:48 WARN TaskSetManager: Stage 59 contains a task of very large size (1003 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(City='Mashhad', min_temp=10.6885, max_temp=15.9385, temp_diff=5.25)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_year_temp = clear_df.withColumn('Year', year(col('dt'))).groupBy('City', 'Year').agg(avg(col('AverageTemperature')).alias('YeaAverageTemperature'))\n",
    "city_year_temp.createOrReplaceTempView('T2')\n",
    "city_temp_range_sql = \"\"\"select City, min(YeaAverageTemperature) as min_temp, max(YeaAverageTemperature) as max_temp from T2 group by City\"\"\"\n",
    "city_temp_range = spark.sql(city_temp_range_sql)\n",
    "city_temp_range = city_temp_range.withColumn('temp_diff', col('max_temp') - col('min_temp'))\n",
    "city_temp_range.orderBy(col('temp_diff').desc()).first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самая большая средняя разница между средней температурой января и средней температурой июля."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/03 16:17:34 WARN TaskSetManager: Stage 89 contains a task of very large size (1003 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/07/03 16:17:34 WARN TaskSetManager: Stage 90 contains a task of very large size (1003 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(City='Harbin', jan_avg=-18.578421875000004, jul_avg=23.414296874999998, jan_jul_diff=41.99271875)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "january_temp = clear_df.filter(month(col('dt')) == 1).groupBy('City').agg(avg(col('AverageTemperature')).alias('jan_avg'))\n",
    "july_temp = clear_df.filter(month(col('dt')) == 7).groupBy('City').agg(avg(col('AverageTemperature')).alias('jul_avg'))\n",
    "\n",
    "city_jan_jul_diff = january_temp.join(july_temp, on=\"City\").withColumn(\"jan_jul_diff\", col(\"jul_avg\") - col(\"jan_avg\"))\n",
    "city_jan_jul_diff.orderBy(col(\"jan_jul_diff\").desc()).first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наибольшее среднее количество месяцев с отрицательной температурой в году.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/03 16:20:32 WARN TaskSetManager: Stage 95 contains a task of very large size (1003 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(City='Harbin', avg_neg_temp_months=4.90625)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import count_distinct\n",
    "clear_df = clear_df.withColumn('Month', month(col('dt')))\n",
    "clear_df = clear_df.withColumn('Year', year(col('dt')))\n",
    "\n",
    "negative_temp_months = clear_df.filter(col('AverageTemperature') < 0).groupBy('City', 'Year').agg(count_distinct(col('Month')).alias('neg_temp_months'))\n",
    "avg_neg_temp_months_city = negative_temp_months.groupBy('City').agg(avg(col('neg_temp_months')).alias('avg_neg_temp_months'))\n",
    "\n",
    "avg_neg_temp_months_city.orderBy(col('avg_neg_temp_months').desc()).first()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
